{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d71bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f382733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/data.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450decf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionAggregator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_key='CustomerId'):\n",
    "        self.group_key = group_key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        agg = X.groupby(self.group_key).agg({\n",
    "            'Amount': ['sum', 'mean', 'count', 'std'],\n",
    "            'Value': ['sum', 'mean', 'std'],\n",
    "        })\n",
    "        # Flatten multi-index columns\n",
    "        agg.columns = ['_'.join(col) for col in agg.columns]\n",
    "        agg.reset_index(inplace=True)\n",
    "        return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6730d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_column='TransactionStartTime'):\n",
    "        self.time_column = time_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df[self.time_column] = pd.to_datetime(df[self.time_column])\n",
    "        df['transaction_hour'] = df[self.time_column].dt.hour\n",
    "        df['transaction_day'] = df[self.time_column].dt.day\n",
    "        df['transaction_month'] = df[self.time_column].dt.month\n",
    "        df['transaction_year'] = df[self.time_column].dt.year\n",
    "        return df[[self.time_column, 'transaction_hour', 'transaction_day', 'transaction_month', 'transaction_year']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1111f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is None:\n",
    "            self.columns = X.select_dtypes(include='object').columns.tolist()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        self.encoder.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        encoded = self.encoder.transform(X[self.columns])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=self.encoder.get_feature_names_out(self.columns), index=X.index)\n",
    "        X = X.drop(columns=self.columns).re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7515b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='mean'):\n",
    "        self.strategy = strategy\n",
    "        self.imputer = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "        self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_imputed = pd.DataFrame(self.imputer.transform(X), columns=X.columns, index=X.index)\n",
    "        return X_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbba165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='standard'):\n",
    "        if method == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif method == 'minmax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'standard' or 'minmax'\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(self.scaler.transform(X), columns=X.columns, index=X.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d1e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is None:\n",
    "            self.columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        self.encoder.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        encoded = self.encoder.transform(X[self.columns])\n",
    "        encoded_df = pd.DataFrame(\n",
    "            encoded,\n",
    "            columns=self.encoder.get_feature_names_out(self.columns),\n",
    "            index=X.index\n",
    "        )\n",
    "        X = X.drop(columns=self.columns)\n",
    "        return pd.concat([X.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8351961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the encoder to the correct columns\n",
    "cat_enc = CategoricalEncoder()\n",
    "encoded_df = cat_enc.fit_transform(df_transactions[['ChannelId', 'ProductCategory']])\n",
    "encoded_df['CustomerId'] = df_transactions['CustomerId'].values\n",
    "encoded_df = encoded_df.groupby('CustomerId').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455e5f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionId           0\n",
       "BatchId                 0\n",
       "AccountId               0\n",
       "SubscriptionId          0\n",
       "CustomerId              0\n",
       "CurrencyCode            0\n",
       "CountryCode             0\n",
       "ProviderId              0\n",
       "ProductId               0\n",
       "ProductCategory         0\n",
       "ChannelId               0\n",
       "Amount                  0\n",
       "Value                   0\n",
       "TransactionStartTime    0\n",
       "PricingStrategy         0\n",
       "FraudResult             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_transactions.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc3f644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.fill_values = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype in ['float64', 'int64']:\n",
    "                self.fill_values[col] = X[col].mean()\n",
    "            else:\n",
    "                self.fill_values[col] = X[col].mode()[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.fill_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8e18a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply missing value imputer\n",
    "imputer = MissingValueImputer()\n",
    "df_transactions_imputed = imputer.fit_transform(df_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23dfafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class NumericScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_scaled = X.copy()\n",
    "        X_scaled[self.columns] = self.scaler.transform(X_scaled[self.columns])\n",
    "        return X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cad03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = NumericScaler()\n",
    "df_scaled = scaler.fit_transform(df_transactions_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b76b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TimeFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['TransactionStartTime'] = pd.to_datetime(X['TransactionStartTime'], errors='coerce')\n",
    "        time_features = X[['CustomerId']].copy()\n",
    "        time_features['transaction_hour'] = X['TransactionStartTime'].dt.hour\n",
    "        time_features['transaction_day'] = X['TransactionStartTime'].dt.day\n",
    "        time_features['transaction_month'] = X['TransactionStartTime'].dt.month\n",
    "        time_features['transaction_year'] = X['TransactionStartTime'].dt.year\n",
    "        return time_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d47612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = Pipeline([\n",
    "    ('temporal', TimeFeaturesExtractor()),           # Extract time features first\n",
    "    ('categorical', CategoricalEncoder()),            # Encode categorical features at transaction level\n",
    "    ('imputer', MissingValueImputer()),               # Impute missing transaction data if needed\n",
    "    ('aggregator', TransactionAggregator()),          # Then aggregate at customer level\n",
    "    ('scaler', NumericScaler())                        # Finally scale aggregated features\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba8a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction-level pipeline\n",
    "transaction_pipeline = Pipeline([\n",
    "    ('temporal', TimeFeaturesExtractor()),\n",
    "    ('categorical', CategoricalEncoder()),\n",
    "    ('imputer', MissingValueImputer()),\n",
    "])\n",
    "transaction_features = transaction_pipeline.fit_transform(df_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ad8bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction-level pipeline\n",
    "transaction_pipeline = Pipeline([\n",
    "    ('temporal', TimeFeaturesExtractor()),\n",
    "    ('categorical', CategoricalEncoder()),\n",
    "    ('imputer', MissingValueImputer()),\n",
    "])\n",
    "transaction_features = transaction_pipeline.fit_transform(df_transactions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
